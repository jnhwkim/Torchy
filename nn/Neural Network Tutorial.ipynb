{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Tutorial\n",
    "\n",
    "(This notebook follows a Torch tutorial. http://dp.readthedocs.org/en/latest/neuralnetworktutorial/)\n",
    "\n",
    "We begin with a simple neural network example. The first line loads the dp package, whose first matter of business is to load its dependencies (see init.lua):\n",
    "\n",
    "If you got the error messege `module 'dp' not found:`, \n",
    "try to install via luarocks (http://dp.readthedocs.org/en/latest/).\n",
    "\n",
    "    $> sudo luarocks install dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  XpLog : table: 0x14f180c0\n",
       "  mkdir : function: 0x14f17fe8\n",
       "  FKDKaggle : table: 0x151d1f48\n",
       "  SAVE_DIR : /Users/Calvin/save\n",
       "  ListView : table: 0x14610fe0\n",
       "  is_file : function: 0x14615398\n",
       "  BillionWords : table: 0x15150690\n",
       "  ImageNet : table: 0x14f35310\n",
       "  SequenceView : table: 0x135b2178\n",
       "  SentenceSet : table: 0x145f9a78\n",
       "  TextSet : table: 0x12fa8cc0\n",
       "  Cifar100 : table: 0x15190ee8\n",
       "  NotMnist : table: 0x14f705b0\n",
       "  download_file : function: 0x14efb188\n",
       "  reverseDist : function: 0x15171f68\n",
       "  XpLogEntry : table: 0x151a2308\n",
       "  FaceDetection : table: 0x14ed45a0\n",
       "  Preprocess : table: 0x15158eb0\n",
       "  AdaptiveDecay : table: 0x151e5d70\n",
       "  Pipeline : table: 0x1512c520\n",
       "  reload : function: 0x14f2f2d8\n",
       "  SaveToFile : table: 0x151e1ec0\n",
       "  printG : function: 0x14f5f810\n",
       "  Perplexity : table: 0x151c8c28\n",
       "  distReport : function: 0x151709c8\n",
       "  Standardize : table: 0x15148c40\n",
       "  unzip : function: 0x15163248\n",
       "  images2tensor : function: 0x14f2f2b8\n",
       "  Channel : table: 0x14f71250\n",
       "  decompress_tarball : function: 0x14f750f8\n",
       "  ObjectID : table: 0x1519cf78\n",
       "  testCuda : function: 0x162901a0\n",
       "  Mediator : table: 0x15138b88\n",
       "  TextSource : table: 0x1516d2f0\n",
       "  View : table: 0x14550ce0\n",
       "  FacialKeypointFeedback : table: 0x151d3f90\n",
       "  DATA_DIR : /Users/Calvin/data\n",
       "  DataView : table: 0x14ec48e0\n",
       "  ClassView : table: 0x14f5af78\n",
       "  EarlyStopper : table: 0x151dec68\n",
       "  vprint : function: 0x14563b60\n",
       "  testDatasets : function: 0x162958a0\n",
       "  SentenceSampler : table: 0x14f5ae40\n",
       "  test : function: 0x151f4cf0\n",
       "  ImageSource : table: 0x1518a2f8\n",
       "  FileLogger : table: 0x151e7b80\n",
       "  DataSet : table: 0x14f6c240\n",
       "  returnString : function: 0x15166010\n",
       "  CompositeFeedback : table: 0x151c39a8\n",
       "  ErrorMinima : table: 0x151dcc58\n",
       "  Experiment : table: 0x151b84e0\n",
       "  PennTreeBank : table: 0x14ee9cf8\n",
       "  Mnist : table: 0x15142d10\n",
       "  Binarize : table: 0x14f449e8\n",
       "  CompositeObserver : table: 0x151d9410\n",
       "  Observer : table: 0x151d73c0\n",
       "  BaseSet : table: 0x14eaec20\n",
       "  do_with_cwd : function: 0x12da9380\n",
       "  Confusion : table: 0x151c7348\n",
       "  Cifar10 : table: 0x14f66288\n",
       "  Feedback : table: 0x151c0218\n",
       "  ParallelPreprocess : table: 0x1514e6d8\n",
       "  ZCA : table: 0x14ed0948\n",
       "  TopCrop : table: 0x151cba80\n",
       "  Logger : table: 0x151dae80\n",
       "  gunzip : function: 0x15168988\n",
       "  RandomSampler : table: 0x14ef1638\n",
       "  Svhn : table: 0x14ef5518\n",
       "  Optimizer : table: 0x151b5cf8\n",
       "  Propagator : table: 0x151afec0\n",
       "  TextSampler : table: 0x1515ae18\n",
       "  ImageClassSet : table: 0x145861b0\n",
       "  Sampler : table: 0x15133a28\n",
       "  ImageView : table: 0x15131a58\n",
       "  uniqueID : function: 0x1516e5c8\n",
       "  TORCH_DIR : /Users/Calvin\n",
       "  check_and_download_file : function: 0x15181088\n",
       "  DataSource : table: 0x15176818\n",
       "  LOG_DIR : /Users/Calvin/log\n",
       "  GCN : table: 0x14f262e0\n",
       "  SmallImageSource : table: 0x14ed9838\n",
       "  FacialKeypoints : table: 0x14f69238\n",
       "  decompress_file : function: 0x15172e28\n",
       "  Subscriber : table: 0x14f37cf0\n",
       "  countFiles : function: 0x145fb248\n",
       "  UNIT_DIR : /Users/Calvin/unit\n",
       "  Batch : table: 0x1457e0f8\n",
       "  check_and_mkdir : function: 0x14f17fe8\n",
       "  LeCunLCN : table: 0x14f123e8\n",
       "  Queue : table: 0x151704e8\n",
       "  ShuffleSampler : table: 0x15193fb8\n",
       "  Evaluator : table: 0x151b6fe8\n",
       "}\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'dp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command-line Arguments\n",
    "\n",
    "Lets define some command-line arguments. These will be stored into table `opt`, which will be printed when the script is launched. Command-line arguments make it easy to control the experiment and try out different hyper-parameters without needing to modify any code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "   batchNorm : false\n",
       "   batchSize : 32\n",
       "   cuda : false\n",
       "   dataset : \"Mnist\"\n",
       "   decayFactor : 0.001\n",
       "   dropout : false\n",
       "   hiddenSize : {200,200}\n",
       "   learningRate : 0.1\n",
       "   lrDecay : \"linear\"\n",
       "   maxEpoch : 100\n",
       "   maxOutNorm : 1\n",
       "   maxTries : 30\n",
       "   maxWait : 4\n",
       "   minLR : 1e-05\n",
       "   momentum : 0\n",
       "   progress : false\n",
       "   saturateEpoch : 300\n",
       "   schedule : {}\n",
       "   silent : false\n",
       "   standardize : false\n",
       "   useDevice : 1\n",
       "   zca : false\n",
       "}\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--[[command line arguments]]--\n",
    "cmd = torch.CmdLine()\n",
    "cmd:text()\n",
    "cmd:text('Image Classification using MLP Training/Optimization')\n",
    "cmd:text('Example:')\n",
    "cmd:text('$> th neuralnetwork.lua --batchSize 128 --momentum 0.5')\n",
    "cmd:text('Options:')\n",
    "cmd:option('--learningRate', 0.1, 'learning rate at t=0')\n",
    "cmd:option('--lrDecay', 'linear', 'type of learning rate decay : adaptive | linear | schedule | none')\n",
    "cmd:option('--minLR', 0.00001, 'minimum learning rate')\n",
    "cmd:option('--saturateEpoch', 300, 'epoch at which linear decayed LR will reach minLR')\n",
    "cmd:option('--schedule', '{}', 'learning rate schedule')\n",
    "cmd:option('--maxWait', 4, 'maximum number of epochs to wait for a new minima to be found. After that, the learning rate is decayed by decayFactor.')\n",
    "cmd:option('--decayFactor', 0.001, 'factor by which learning rate is decayed for adaptive decay.')\n",
    "cmd:option('--maxOutNorm', 1, 'max norm each layers output neuron weights')\n",
    "cmd:option('--momentum', 0, 'momentum')\n",
    "cmd:option('--hiddenSize', '{200,200}', 'number of hidden units per layer')\n",
    "cmd:option('--batchSize', 32, 'number of examples per batch')\n",
    "cmd:option('--cuda', false, 'use CUDA')\n",
    "cmd:option('--useDevice', 1, 'sets the device (GPU) to use')\n",
    "cmd:option('--maxEpoch', 100, 'maximum number of epochs to run')\n",
    "cmd:option('--maxTries', 30, 'maximum number of epochs to try to find a better local minima for early-stopping')\n",
    "cmd:option('--dropout', false, 'apply dropout on hidden neurons')\n",
    "cmd:option('--batchNorm', false, 'use batch normalization. dropout is mostly redundant with this')\n",
    "cmd:option('--dataset', 'Mnist', 'which dataset to use : Mnist | NotMnist | Cifar10 | Cifar100')\n",
    "cmd:option('--standardize', false, 'apply Standardize preprocessing')\n",
    "cmd:option('--zca', false, 'apply Zero-Component Analysis whitening')\n",
    "cmd:option('--progress', false, 'display progress bar')\n",
    "cmd:option('--silent', false, 'dont print anything to stdout')\n",
    "cmd:text()\n",
    "opt = cmd:parse(arg or {})\n",
    "opt.schedule = dp.returnString(opt.schedule)\n",
    "opt.hiddenSize = dp.returnString(opt.hiddenSize)\n",
    "if not opt.silent then\n",
    "   table.print(opt)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "\n",
    "The `--standardize` and `--zca` cmd-line arguments can be toggled on to perform some preprocessing on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--[[preprocessing]]--\n",
    "local input_preprocess = {}\n",
    "if opt.standardize then\n",
    "   table.insert(input_preprocess, dp.Standardize())\n",
    "end\n",
    "if opt.zca then\n",
    "   table.insert(input_preprocess, dp.ZCA())\n",
    "end\n",
    "if opt.lecunlcn then\n",
    "   table.insert(input_preprocess, dp.GCN())\n",
    "   table.insert(input_preprocess, dp.LeCunLCN{progress=true})\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very common and easy preprocessing technique is to Standardize the datasource, which subtracts the mean and divides by the standard deviation. Both statistics (mean and standard deviation) are measured on the `train` set only. This is a common pattern when preprocessing data. When statistics need to be measured across different examples (as in ZCA and LecunLCN preprocesses), we fit the preprocessor on the `train` set and apply it to all sets (`train`, `valid` and `test`). However, some preprocesses require that statistics be measured only on each example, as is the case for global constrast normalization ([GCN]](preprocess.md#dp.GCN)), such that there is no fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSource\n",
    "\n",
    "We intend to build and train a neural network so we need some data, which we encapsulate in a DataSource object. dp provides the option of training on different datasets, notably MNIST, NotMNIST, CIFAR-10 or CIFAR-100. The default for this script is the archetypal MNIST (don't leave home without it). However, you can use the `--dataset` argument to specify a different image classification dataset.\n",
    "\n",
    "If you have a trouble to pull `mnist4.zip`, you can manually locate that file in `~/data/mnist/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decompressing file: \t/Users/Calvin/data/mnist/mnist4.zip\t\n",
       "Archive:  /Users/Calvin/data/mnist/mnist4.zip\n",
       "  inflating: ./train.th7             "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  inflating: ./test.th7              \n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--[[data]]--\n",
    "\n",
    "if opt.dataset == 'Mnist' then\n",
    "   ds = dp.Mnist{input_preprocess = input_preprocess}\n",
    "elseif opt.dataset == 'NotMnist' then\n",
    "   ds = dp.NotMnist{input_preprocess = input_preprocess}\n",
    "elseif opt.dataset == 'Cifar10' then\n",
    "   ds = dp.Cifar10{input_preprocess = input_preprocess}\n",
    "elseif opt.dataset == 'Cifar100' then\n",
    "   ds = dp.Cifar100{input_preprocess = input_preprocess}\n",
    "else\n",
    "    error(\"Unknown Dataset\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataSource contains up to three DataSets:  `train`, `valid` and `test`. The first is for training the model. The second is used for early-stopping and cross-validation. The third is used for publishing papers and comparing results across different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model of Modules\n",
    "\n",
    "Ok so we have a DataSource, now we need a model. Let's build a multi-layer perceptron (MLP) with one or more parameterized non-linear layers (note that in the case of hidden layers being ommitted (`--hiddenSize '{}'`), the model is just a linear classifier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--[[Model]]--\n",
    "\n",
    "model = nn.Sequential()\n",
    "model:add(nn.Convert(ds:ioShapes(), 'bf')) -- to batchSize x nFeature (also type converts)\n",
    "\n",
    "-- hidden layers\n",
    "inputSize = ds:featureSize()\n",
    "for i,hiddenSize in ipairs(opt.hiddenSize) do\n",
    "   model:add(nn.Linear(inputSize, hiddenSize)) -- parameters\n",
    "   if opt.batchNorm then\n",
    "      model:add(nn.BatchNormalization(hiddenSize))\n",
    "   end\n",
    "   model:add(nn.Tanh())\n",
    "   if opt.dropout then\n",
    "      model:add(nn.Dropout())\n",
    "   end\n",
    "   inputSize = hiddenSize\n",
    "end\n",
    "\n",
    "-- output layer\n",
    "model:add(nn.Linear(inputSize, #(ds:classes())))\n",
    "model:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output and hidden layers are defined using a Linear, which contains the parameters that will be learned, followed by a non-linear transfer function like Tanh (for the hidden neurons) and LogSoftMax (for the output layer). The latter might seem odd (why not use SoftMax instead?), but the ClassNLLCriterion only works with LogSoftMax (or with SoftMax + Log).\n",
    "\n",
    "The Linear modules are constructed using 2 arguments,  `inputSize` (number of input units) and `outputSize` (number of output units). For the first layer, the `inputSize` is the number of features in the input image. In our case, that is `1x28x28=784`, which is what `ds:featureSize()` will return.\n",
    "\n",
    "Now for the odd looking nn.Convert Module. It has two purposes. First, whatever type of Tensor received, it will output the type of Tensor used by the Module. Second, it can convert from different Tensor `shapes`. The `shape` of a typical image is bchw, short for batch, color/channel, height and width. Modules like SpatialConvolution and SpatialMaxPooling expect this type of input. Our MLP, on the other hand, expects an input of shape bf, short for batch, feature. Its a pretty simple conversion actually, all you need to do is flatten the chw dimensions to a single f dimension (in this case, of size 784).\n",
    "\n",
    "For those not familiar with the nn package, all the `nn.*` in the above snippet of code are Module subclasses. This is true even for the Sequential. Although the latter is special. It is a Container of other Modules, i.e. a composite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagator\n",
    "\n",
    "Next we initialize some Propagators. Each such Propagator will propagate examples from a different DataSet. Samplers iterate over DataSets to generate Batches of examples (inputs and targets) to propagate through the `model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--[[Propagators]]--\n",
    "if opt.lrDecay == 'adaptive' then\n",
    "   ad = dp.AdaptiveDecay{max_wait = opt.maxWait, decay_factor=opt.decayFactor}\n",
    "elseif opt.lrDecay == 'linear' then\n",
    "   opt.decayFactor = (opt.minLR - opt.learningRate)/opt.saturateEpoch\n",
    "end\n",
    "\n",
    "train = dp.Optimizer{\n",
    "   acc_update = opt.accUpdate,\n",
    "   loss = nn.ModuleCriterion(nn.ClassNLLCriterion(), nil, nn.Convert()),\n",
    "   epoch_callback = function(model, report) -- called every epoch\n",
    "      -- learning rate decay\n",
    "      if report.epoch > 0 then\n",
    "         if opt.lrDecay == 'adaptive' then\n",
    "            opt.learningRate = opt.learningRate*ad.decay\n",
    "            ad.decay = 1\n",
    "         elseif opt.lrDecay == 'schedule' and opt.schedule[report.epoch] then\n",
    "            opt.learningRate = opt.schedule[report.epoch]\n",
    "         elseif opt.lrDecay == 'linear' then \n",
    "            opt.learningRate = opt.learningRate + opt.decayFactor\n",
    "         end\n",
    "         opt.learningRate = math.max(opt.minLR, opt.learningRate)\n",
    "         if not opt.silent then\n",
    "            print(\"learningRate\", opt.learningRate)\n",
    "         end\n",
    "      end\n",
    "   end,\n",
    "   callback = function(model, report) -- called every batch\n",
    "      if opt.accUpdate then\n",
    "         model:accUpdateGradParameters(model.dpnn_input, model.output, opt.learningRate)\n",
    "      else\n",
    "         model:updateGradParameters(opt.momentum) -- affects gradParams\n",
    "         model:updateParameters(opt.learningRate) -- affects params\n",
    "      end\n",
    "      model:maxParamNorm(opt.maxOutNorm) -- affects params\n",
    "      model:zeroGradParameters() -- affects gradParams \n",
    "   end,\n",
    "   feedback = dp.Confusion(),\n",
    "   sampler = dp.ShuffleSampler{batch_size = opt.batchSize},\n",
    "   progress = opt.progress\n",
    "}\n",
    "valid = dp.Evaluator{\n",
    "   feedback = dp.Confusion(),  \n",
    "   sampler = dp.Sampler{batch_size = opt.batchSize}\n",
    "}\n",
    "test = dp.Evaluator{\n",
    "   feedback = dp.Confusion(),\n",
    "   sampler = dp.Sampler{batch_size = opt.batchSize}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we use an Optimizer for the training DataSet, and two Evaluators, one for cross-validation and another for testing. Now lets explore the different constructor arguments.\n",
    "\n",
    "### `sampler`\n",
    "\n",
    "The Evaluators use a simple Sampler which iterates sequentially through the DataSet. On the other hand, the Optimizer uses a ShuffleSampler. This Sampler shuffles the (indices of a) DataSet before each pass over all examples in a DataSet. This shuffling is useful for training since the model must learn from varying sequences of batches through the DataSet. Which makes the training algorithm more stochastic (subject to the constraint that each example is presented once and only once per epoch).\n",
    "\n",
    "### `loss`\n",
    "\n",
    "Each Propagator can also specify a loss for training or evaluation. This argument is only mandatory for the Optimizer, as it is required for backpropagation. If you have previously used the nn package, there is nothing new here. The loss is a Criterion. Each example has a single target class and our Model output is LogSoftMax so we use a ClassNLLCriterion. The criterion is wrapped in ModuleCriterion, which is a decorator that allows us to pass each input and target through a module before it is passed on to the decorated criterion. In our case, we want to make sure each target gets converted to the type of the loss.\n",
    "\n",
    "### `feedback`\n",
    "\n",
    "The feedback parameter is used to provide us with, you guessed it, feedback (like performance measures and statistics after each epoch). We use Confusion, which is a wrapper for the optim package's ConfusionMatrix. While our Loss measures the Negative Log-Likelihood (NLL) of the model on different datasets, our Feedback measures classification accuracy (which is what we will use for early-stopping and comparing our model to the state-of-the-art).\n",
    "\n",
    "### `callback`\n",
    "\n",
    "Since the Optimizer is used to train the model on a DataSet, we need to specify a callback function that will be called after successive forward/backward calls. Among other things, the callback should either updateParameters or accUpdateGradParameters. Depending on what is specified in the command-line, it can also be used to updateGradParameters (commonly known as momentum learning). You can also choose to regularize it with weightDecay or maxParamNorm, (personally, I prefer the latter to the former). In any case, the callback is a function that you can define to fit your needs.\n",
    "\n",
    "### `epoch_callback`\n",
    "\n",
    "While the callback argument is called every batch, the epoch_callback is called between epochs. This is useful for decaying hyper-parameters such as the learning rate, which is what we do in this example. Since the learning rate is the most important hyper-parameter, it is a good idea to try different learning rate decay schedules during hyper-optimization.\n",
    "\n",
    "The --lrDecay 'linear' decay is the easiest to use (the default cmd-line argument). It involves specifying a starting learning rate --learningRate, a minimum learning rate --minLR and the epoch at which that minimum will be reached : --saturateEpoch.\n",
    "\n",
    "The --lrDecay 'adaptive' uses an exponentially decaying learning rate. By default this mode only decays the learning rate when a minima hasn't been found for --maxWait epochs. But by using --maxWait -1, we can decay the learning rate every epoch with the following rule : lr = lr*decayFactor. This will decay the learning rate much faster than a linear decay.\n",
    "\n",
    "Another option (--lrDecayschedule) is to specify the learning rate--schedule` manually by specifying a table mapping learning rates to epochs like '{[200] = 0.01, [300] = 0.001}', which will decay the learning rate to the given value at the given epoch.\n",
    "\n",
    "Of course, because this argument is just another callback function, you can use it however you please by coding your own function.\n",
    "\n",
    "### `acc_update`\n",
    "\n",
    "When set to true, the gradients w.r.t. parameters (a.k.a. gradParameters) are accumulated directly into the parameters (a.k.a. parameters) to produce an update after the forward and backward pass. In other words, for acc_update=true, the sequence for propagating a batch is essentially:\n",
    "\n",
    "1. updateOutput\n",
    "2. updateGradInput\n",
    "3. accUpdateGradParameters\n",
    "\n",
    "Instead of the more common:\n",
    "\n",
    "1. updateOutput\n",
    "2. updateGradInput\n",
    "3. accGradParameters\n",
    "4. updateParameters\n",
    "\n",
    "This means that no gradParameters are actually used internally. The default value if false. Some methods do not work with acc_update as they require the the gradParameters tensors be populated before being added to the parameters. This is the case for updateGradParameters (momentum learning) and weightDecay.\n",
    "\n",
    "### `progress`\n",
    "\n",
    "Finally, we allow for the Optimizer's progress bar to be switched on so that we can monitor training progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "Now its time to put this all together to form an Experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--[[Experiment]]--\n",
    "\n",
    "xp = dp.Experiment{\n",
    "   model = model,\n",
    "   optimizer = train,\n",
    "   validator = valid,\n",
    "   tester = test,\n",
    "   observer = {\n",
    "      dp.FileLogger(),\n",
    "      dp.EarlyStopper{\n",
    "         error_report = {'validator','feedback','confusion','accuracy'},\n",
    "         maximize = true,\n",
    "         max_epochs = opt.maxTries\n",
    "      }\n",
    "   },\n",
    "   random_seed = os.time(),\n",
    "   max_epoch = opt.maxEpoch\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observer\n",
    "\n",
    "The Experiment can be initialized using a list of Observers. The order is not important. Observers listen to mediator Channels. The Mediator calls them back when certain events occur. In particular, they may listen to the doneEpoch Channel to receive a report from the Experiment after each epoch. A report is nothing more than a bunch of nested tables matching the object structure of the experiment. After each epoch, the component objects of the Experiment (except Observers) can each submit a report to its composite parent thereby forming a tree of reports. The Observers can analyse these and modify the components which they are assigned to (in this case, Experiment). Observers may be attached to Experiments, Propagators, Visitors, etc.\n",
    "\n",
    "### FileLogger\n",
    "\n",
    "Here we use a simple FileLogger which will store serialized reports in a simple text file for later use. Each experiment has a unique ID which is included in the corresponding reports, thus allowing the FileLogger to name its file appropriately.\n",
    "\n",
    "### EarlyStopper\n",
    "\n",
    "The EarlyStopper is used for stopping the Experiment when the error has not decreased, or accuracy has not been maximized. It also saves to disk the best version of the Experiment when it finds a new one. It is initialized with a channel to maximize or minimize (the default is to minimize). In this case, we intend to early-stop the experiment on a field of the report, in particular the accuracy field of the confusion table of the feedback table of the validator. This {'validator','feedback','confusion','accuracy'} happens to measure the accuracy of the Model on the validation DataSet after each training epoch. So by early-stopping on this measure, we hope to find a Model that generalizes well. The parameter max_epochs indicates how many consecutive epochs of training can occur without finding a new best model before the experiment is signaled to stop by the doneExperiment Mediator Channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Experiment\n",
    "\n",
    "Once we have initialized the experiment, we need only run it on the datasource to begin training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==> epoch # 1 for optimizer :\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12005.248724198 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.012680900638777\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.8883\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9205\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9254\t\n",
       "==> epoch # 2 for optimizer :\t\n",
       "learningRate\t0.0996667\t\n",
       "==> example speed = 12960.909405483 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0072663029688749\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.93184\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9406\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9446\t\n",
       "==> epoch # 3 for optimizer :\t\n",
       "learningRate\t0.0993334\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13045.26678063 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0057252667801146\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9477\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.949\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.95\t\n",
       "==> epoch # 4 for optimizer :\t\n",
       "learningRate\t0.0990001\t\n",
       "==> example speed = 12711.484342217 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0047952777237153\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.95654\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9563\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9566\t\n",
       "==> epoch # 5 for optimizer :\t\n",
       "learningRate\t0.0986668\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13002.122534108 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0041577624015475\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.96222\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9598\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9603\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 6 for optimizer :\t\n",
       "learningRate\t0.0983335\t\n",
       "==> example speed = 12262.992596543 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0037269017884712\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.96636\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9628\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9631\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 7 for optimizer :\t\n",
       "learningRate\t0.0980002\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12928.291833463 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0033465400241032\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.96964\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9669\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9652\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 8 for optimizer :\t\n",
       "learningRate\t0.0976669\t\n",
       "==> example speed = 11338.133065433 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0030726780987977\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.97288\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9661\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9663\t\n",
       "==> epoch # 9 for optimizer :\t\n",
       "learningRate\t0.0973336\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12318.769495228 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0028642991677042\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9748\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9664\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9679\t\n",
       "==> epoch # 10 for optimizer :\t\n",
       "learningRate\t0.0970003\t\n",
       "==> example speed = 12799.475802718 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.002672306250463\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.97662\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9676\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9695\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 11 for optimizer :\t\n",
       "learningRate\t0.096667\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12933.251007265 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0025164904230903\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.97924\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9697\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9684\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 12 for optimizer :\t\n",
       "learningRate\t0.0963337\t\n",
       "==> example speed = 12980.145468599 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0023981546546169\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98002\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9718\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9722\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 13 for optimizer :\t\n",
       "learningRate\t0.0960004\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12046.276867368 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0022687325645182\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98128\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9705\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9714\t\n",
       "==> epoch # 14 for optimizer :\t\n",
       "learningRate\t0.0956671\t\n",
       "==> example speed = 12913.863323715 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0021489548732926\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98294\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9718\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9739\t\n",
       "==> epoch # 15 for optimizer :\t\n",
       "learningRate\t0.0953338\t\n",
       "==> example speed = 11846.053587165 examples/s\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0020779247435501\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98274\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9737\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.975\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 16 for optimizer :\t\n",
       "learningRate\t0.0950005\t\n",
       "==> example speed = 12369.682424787 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0019733026542487\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98408\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9746\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9745\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 17 for optimizer :\t\n",
       "learningRate\t0.0946672\t\n",
       "==> example speed = 13032.841124962 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0019218221888643\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98478\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9721\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9725\t\n",
       "==> epoch # 18 for optimizer :\t\n",
       "learningRate\t0.0943339\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12864.178778637 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0018303194976572\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98622\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9751\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9748\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 19 for optimizer :\t\n",
       "learningRate\t0.0940006\t\n",
       "==> example speed = 11896.983785762 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.001781126733682\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98666\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9744\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9761\t\n",
       "==> epoch # 20 for optimizer :\t\n",
       "learningRate\t0.0936673\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 11320.007783628 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0017280557069612\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98704\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9767\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9763\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 21 for optimizer :\t\n",
       "learningRate\t0.093334\t\n",
       "==> example speed = 12563.764571518 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.001667178212658\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98766\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9771\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9767\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 22 for optimizer :\t\n",
       "learningRate\t0.0930007\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12118.086206913 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0016241946991758\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98826\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9754\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.977\t\n",
       "==> epoch # 23 for optimizer :\t\n",
       "learningRate\t0.0926674\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12303.297901387 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0015961189712455\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98844\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9713\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9764\t\n",
       "==> epoch # 24 for optimizer :\t\n",
       "learningRate\t0.0923341\t\n",
       "==> example speed = 12569.045326434 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0015394483816462\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98946\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9727\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9748\t\n",
       "==> epoch # 25 for optimizer :\t\n",
       "learningRate\t0.0920008\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12892.013758107 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0015102322104702\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.98934\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9768\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9782\t\n",
       "==> epoch # 26 for optimizer :\t\n",
       "learningRate\t0.0916675\t\n",
       "==> example speed = 12870.364381047 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.001476799684578\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9897\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9709\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9725\t\n",
       "==> epoch # 27 for optimizer :\t\n",
       "learningRate\t0.0913342\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12588.652929282 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0014476106598127\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99032\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.977\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9784\t\n",
       "==> epoch # 28 for optimizer :\t\n",
       "learningRate\t0.0910009\t\n",
       "==> example speed = 11468.86854441 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0014155623099914\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99086\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9754\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9772\t\n",
       "==> epoch # 29 for optimizer :\t\n",
       "learningRate\t0.0906676\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12954.334000914 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0013904414211491\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9907\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9778\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9787\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 30 for optimizer :\t\n",
       "learningRate\t0.0903343\t\n",
       "==> example speed = 13082.909126162 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0013618815349777\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9916\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9783\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9789\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 31 for optimizer :\t\n",
       "learningRate\t0.090001\t\n",
       "==> example speed = 12358.308881232 examples/s\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0013367883618983\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99162\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9763\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9797\t\n",
       "==> epoch # 32 for optimizer :\t\n",
       "learningRate\t0.0896677\t\n",
       "==> example speed = 13037.310239136 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0013128595637443\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99198\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9778\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9795\t\n",
       "==> epoch # 33 for optimizer :\t\n",
       "learningRate\t0.0893344\t\n",
       "==> example speed = 12465.361645228 examples/s\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0012823231851735\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99224\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9787\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9782\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 34 for optimizer :\t\n",
       "learningRate\t0.0890011\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12692.49801244 examples/s\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0012714623908622\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9924\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9783\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9799\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> epoch # 35 for optimizer :\t\n",
       "learningRate\t0.0886678\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12845.836207919 examples/s\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0012593490944031\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99222\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.978\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.98\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> epoch # 36 for optimizer :\t\n",
       "learningRate\t0.0883345\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12365.197716502 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0012318011223081\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9929\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9764\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9794\t\n",
       "==> epoch # 37 for optimizer :\t\n",
       "learningRate\t0.0880012\t\n",
       "==> example speed = 11416.19533137 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0012317491399752\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99256\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9779\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.979\t\n",
       "==> epoch # 38 for optimizer :\t\n",
       "learningRate\t0.0876679\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12250.401555647 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0012069451313965\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99256\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9779\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9787\t\n",
       "==> epoch # 39 for optimizer :\t\n",
       "learningRate\t0.0873346\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12564.4209417 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0011909162897546\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99322\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9787\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.98\t\n",
       "==> epoch # 40 for optimizer :\t\n",
       "learningRate\t0.0870013\t\n",
       "==> example speed = 13023.912891056 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0011829063401755\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99312\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9784\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9803\t\n",
       "==> epoch # 41 for optimizer :\t\n",
       "learningRate\t0.086668\t\n",
       "==> example speed = 12988.436174948 examples/s\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0011556369835593\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99392\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9791\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.979\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 42 for optimizer :\t\n",
       "learningRate\t0.0863347\t\n",
       "==> example speed = 13018.392593972 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0011491813484371\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99358\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9767\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9802\t\n",
       "==> epoch # 43 for optimizer :\t\n",
       "learningRate\t0.0860014\t\n",
       "==> example speed = 12983.566423154 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0011346706456584\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99444\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9793\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9803\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 44 for optimizer :\t\n",
       "learningRate\t0.0856681\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12973.318595425 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0011345734376488\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99378\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9809\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9803\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 45 for optimizer :\t\n",
       "learningRate\t0.0853348\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12813.042181669 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0011104919509359\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99414\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9773\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9786\t\n",
       "==> epoch # 46 for optimizer :\t\n",
       "learningRate\t0.0850015\t\n",
       "==> example speed = 11389.238693538 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0011151399677256\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99426\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9788\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9794\t\n",
       "==> epoch # 47 for optimizer :\t\n",
       "learningRate\t0.0846682\t\n",
       "==> example speed = 12846.376800231 examples/s\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0010887182846636\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99444\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9791\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9803\t\n",
       "==> epoch # 48 for optimizer :\t\n",
       "learningRate\t0.0843349\t\n",
       "==> example speed = 12986.234041543 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0010840497986231\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99454\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9789\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9803\t\n",
       "==> epoch # 49 for optimizer :\t\n",
       "learningRate\t0.0840016\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12655.06536136 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0010750676081854\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99454\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9806\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9814\t\n",
       "==> epoch # 50 for optimizer :\t\n",
       "learningRate\t0.0836683\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12358.351848892 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0010603279452475\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99452\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9802\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9803\t\n",
       "==> epoch # 51 for optimizer :\t\n",
       "learningRate\t0.083335\t\n",
       "==> example speed = 13001.056933497 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0010524556404985\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99484\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9794\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9804\t\n",
       "==> epoch # 52 for optimizer :\t\n",
       "learningRate\t0.0830017\t\n",
       "==> example speed = 12995.343393946 examples/s\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0010489264100897\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.995\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.98\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9822\t\n",
       "==> epoch # 53 for optimizer :\t\n",
       "learningRate\t0.0826684\t\n",
       "==> example speed = 13040.662464897 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0010330553910676\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99512\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9798\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9818\t\n",
       "==> epoch # 54 for optimizer :\t\n",
       "learningRate\t0.0823351\t\n",
       "==> example speed = 12822.353814209 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0010402103082934\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99466\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9789\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9797\t\n",
       "==> epoch # 55 for optimizer :\t\n",
       "learningRate\t0.0820018\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13003.834147838 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0010282927425012\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99516\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9772\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9807\t\n",
       "==> epoch # 56 for optimizer :\t\n",
       "learningRate\t0.0816685\t\n",
       "==> example speed = 13017.321900935 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0010138760337517\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99512\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9807\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9811\t\n",
       "==> epoch # 57 for optimizer :\t\n",
       "learningRate\t0.0813352\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13023.577238499 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0010136864885497\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9953\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9791\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9809\t\n",
       "==> epoch # 58 for optimizer :\t\n",
       "learningRate\t0.0810019\t\n",
       "==> example speed = 12997.336761688 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0010063021545357\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99514\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.98\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9817\t\n",
       "==> epoch # 59 for optimizer :\t\n",
       "learningRate\t0.0806686\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13009.734322887 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0010001659140171\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99522\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.98\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9814\t\n",
       "==> epoch # 60 for optimizer :\t\n",
       "learningRate\t0.0803353\t\n",
       "==> example speed = 13024.584248078 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00098899253424316\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99548\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9804\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9821\t\n",
       "==> epoch # 61 for optimizer :\t\n",
       "learningRate\t0.080002\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13026.630291646 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00098585489293185\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99538\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9811\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9831\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 62 for optimizer :\t\n",
       "learningRate\t0.0796687\t\n",
       "==> example speed = 13027.356957626 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00097453959869528\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99562\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9799\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9813\t\n",
       "==> epoch # 63 for optimizer :\t\n",
       "learningRate\t0.0793354\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13013.594031481 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00096692859466214\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9959\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9794\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9816\t\n",
       "==> epoch # 64 for optimizer :\t\n",
       "learningRate\t0.0790021\t\n",
       "==> example speed = 13056.599962881 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00097182100964989\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9956\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.981\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9809\t\n",
       "==> epoch # 65 for optimizer :\t\n",
       "learningRate\t0.0786688\t\n",
       "==> example speed = 13046.015005002 examples/s\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00096308701916634\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99584\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.981\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9813\t\n",
       "==> epoch # 66 for optimizer :\t\n",
       "learningRate\t0.0783355\t\n",
       "==> example speed = 13026.043677252 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.000959024777077\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99586\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.98\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9817\t\n",
       "==> epoch # 67 for optimizer :\t\n",
       "learningRate\t0.0780022\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12928.860111673 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00095222550375682\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99576\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.98\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9812\t\n",
       "==> epoch # 68 for optimizer :\t\n",
       "learningRate\t0.0776689\t\n",
       "==> example speed = 13064.851915622 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00094910704690601\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99606\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9807\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.982\t\n",
       "==> epoch # 69 for optimizer :\t\n",
       "learningRate\t0.0773356\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13014.356394876 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0009482668412729\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99594\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9765\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9783\t\n",
       "==> epoch # 70 for optimizer :\t\n",
       "learningRate\t0.0770023\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13004.01315561 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00094365990315384\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99584\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9812\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.982\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 71 for optimizer :\t\n",
       "learningRate\t0.076669\t\n",
       "==> example speed = 13054.557496894 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00093214907624351\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99618\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9797\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9817\t\n",
       "==> epoch # 72 for optimizer :\t\n",
       "learningRate\t0.0763357\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13051.180255848 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00092384555260832\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99624\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9799\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9811\t\n",
       "==> epoch # 73 for optimizer :\t\n",
       "learningRate\t0.0760024\t\n",
       "==> example speed = 13020.226514412 examples/s\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00092541953881822\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99604\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9794\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9809\t\n",
       "==> epoch # 74 for optimizer :\t\n",
       "learningRate\t0.0756691\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12973.530472163 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00091730438716163\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9964\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9812\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.982\t\n",
       "==> epoch # 75 for optimizer :\t\n",
       "learningRate\t0.0753358\t\n",
       "==> example speed = 13085.950052858 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0009177488588405\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99658\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9776\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9759\t\n",
       "==> epoch # 76 for optimizer :\t\n",
       "learningRate\t0.0750025\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13059.065102225 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00090949309777768\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99634\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9711\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9728\t\n",
       "==> epoch # 77 for optimizer :\t\n",
       "learningRate\t0.0746692\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13025.802573829 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00090860059405899\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99652\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9819\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9825\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 78 for optimizer :\t\n",
       "learningRate\t0.0743359\t\n",
       "==> example speed = 13058.96670647 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00090616522434592\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99638\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9802\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9822\t\n",
       "==> epoch # 79 for optimizer :\t\n",
       "learningRate\t0.0740026\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13056.746284218 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00090109108263381\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9964\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9803\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9808\t\n",
       "==> epoch # 80 for optimizer :\t\n",
       "learningRate\t0.0736693\t\n",
       "==> example speed = 13067.457777319 examples/s\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0008967868474894\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99638\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9811\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9818\t\n",
       "==> epoch # 81 for optimizer :\t\n",
       "learningRate\t0.073336\t\n",
       "==> example speed = 13066.958667414 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00089859647202261\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9965\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9806\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9817\t\n",
       "==> epoch # 82 for optimizer :\t\n",
       "learningRate\t0.0730027\t\n",
       "==> example speed = 13053.650661574 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00089533807013431\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99664\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9817\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9823\t\n",
       "==> epoch # 83 for optimizer :\t\n",
       "learningRate\t0.0726694\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13052.370255649 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00088304498327732\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99648\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9808\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9814\t\n",
       "==> epoch # 84 for optimizer :\t\n",
       "learningRate\t0.0723361\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13071.67364198 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.000885516645372\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99648\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9806\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9825\t\n",
       "==> epoch # 85 for optimizer :\t\n",
       "learningRate\t0.0720028\t\n",
       "==> example speed = 13057.016174397 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00088330774408195\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99652\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9799\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9822\t\n",
       "==> epoch # 86 for optimizer :\t\n",
       "learningRate\t0.0716695\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13054.832985261 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00088214082166616\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99652\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9809\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9818\t\n",
       "==> epoch # 87 for optimizer :\t\n",
       "learningRate\t0.0713362\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13058.699988244 examples/s\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00087362034735549\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99682\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.982\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9829\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 88 for optimizer :\t\n",
       "learningRate\t0.0710029\t\n",
       "==> example speed = 12999.874659793 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00087125914070715\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99672\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9809\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.982\t\n",
       "==> epoch # 89 for optimizer :\t\n",
       "learningRate\t0.0706696\t\n",
       "==> example speed = 13069.237133437 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00086763750401841\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99668\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9823\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9827\t\n",
       "SaveToFile: saving to /Users/Calvin/save/Mingming.local:1438830384:1.dat\t\n",
       "==> epoch # 90 for optimizer :\t\n",
       "learningRate\t0.0703363\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13055.877346152 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00086284329332613\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9968\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9797\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9803\t\n",
       "==> epoch # 91 for optimizer :\t\n",
       "learningRate\t0.070003\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12692.133904472 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00086367925535907\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99672\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9815\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9826\t\n",
       "==> epoch # 92 for optimizer :\t\n",
       "learningRate\t0.0696697\t\n",
       "==> example speed = 13088.734250111 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.0008640336190396\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99678\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.981\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9815\t\n",
       "==> epoch # 93 for optimizer :\t\n",
       "learningRate\t0.0693364\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13005.64622431 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00085610268385092\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99706\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9814\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9818\t\n",
       "==> epoch # 94 for optimizer :\t\n",
       "learningRate\t0.0690031\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13078.21703627 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00085911493317722\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99674\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9817\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9824\t\n",
       "==> epoch # 95 for optimizer :\t\n",
       "learningRate\t0.068669800000001\t\n",
       "==> example speed = 13078.805912364 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00086003277828493\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99708\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9804\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9833\t\n",
       "==> epoch # 96 for optimizer :\t\n",
       "learningRate\t0.068336500000001\t\n",
       "==> example speed = 13066.351319188 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00084473250915891\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99712\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9819\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9824\t\n",
       "==> epoch # 97 for optimizer :\t\n",
       "learningRate\t0.068003200000001\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13025.551771014 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00084968017767125\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99694\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9814\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9818\t\n",
       "==> epoch # 98 for optimizer :\t\n",
       "learningRate\t0.067669900000001\t\n",
       "==> example speed = 13095.82055043 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00084763783664583\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99714\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9822\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9827\t\n",
       "==> epoch # 99 for optimizer :\t\n",
       "learningRate\t0.067336600000001\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 13088.539832368 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00084568746335509\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.99702\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.982\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9833\t\n",
       "==> epoch # 100 for optimizer :\t\n",
       "learningRate\t0.067003300000001\t\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "==> example speed = 12995.887784398 examples/s\t\n",
       "Mingming.local:1438830384:1:optimizer:loss avgErr 0.00083685147374363\t\n",
       "Mingming.local:1438830384:1:optimizer:confusion accuracy = 0.9972\t\n",
       "Mingming.local:1438830384:1:validator:confusion accuracy = 0.9806\t\n",
       "Mingming.local:1438830384:1:tester:confusion accuracy = 0.9816\t\n",
       "\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp:run(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't initialize the Experiment with the DataSource so that we may easily save it to disk, thereby keeping this snapshot separate from its data (which shouldn't be modified by the experiment).\n",
    "\n",
    "Let's run the script from the cmd-line (with default arguments):\n",
    "\n",
    "    nicholas@xps:~/projects/dp$ th examples/neuralnetwork.lua\n",
    "\n",
    "First it prints the command-line arguments stored in opt:\n",
    "\n",
    "    {\n",
    "       batchNorm : false\n",
    "       batchSize : 32\n",
    "       cuda : false\n",
    "       dataset : \"Mnist\"\n",
    "       dropout : false\n",
    "       hiddenSize : {200,200}\n",
    "       learningRate : 0.1\n",
    "       lecunlcn : false\n",
    "       maxEpoch : 100\n",
    "       maxOutNorm : 1\n",
    "       maxTries : 30\n",
    "       momentum : 0\n",
    "       progress : false\n",
    "       schedule : {[200]=0.01,[400]=0.001}\n",
    "       silent : false\n",
    "       standardize : false\n",
    "       useDevice : 1\n",
    "       zca : false\n",
    "    }  \n",
    "\n",
    "After that it prints the model.\n",
    "\n",
    "    Model : \n",
    "    nn.Sequential {\n",
    "      [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> output]\n",
    "      (1): nn.Convert\n",
    "      (2): nn.Linear(784 -> 200)\n",
    "      (3): nn.Tanh\n",
    "      (4): nn.Linear(200 -> 200)\n",
    "      (5): nn.Tanh\n",
    "      (6): nn.Linear(200 -> 10)\n",
    "      (7): nn.LogSoftMax\n",
    "    }\n",
    "\n",
    "The `FileLogger` then prints where the epoch logs will be saved. This can be controlled with the `$TORCH_DATA_PATH` or `$DEEP_SAVE_PATH` environment variables. It defaults to $HOME/save.\n",
    "\n",
    "    FileLogger: log will be written to /home/nicholas/save/xps:1432747515:1/log \n",
    "    \n",
    "Finally, we get to the fun part : the actual training. Every epoch, some performance data gets printed to `stdout`:\n",
    "\n",
    "    ==> epoch # 1 for optimizer :   \n",
    "    ==> example speed = 4508.3691689025 examples/s  \n",
    "    xps:1432747515:1:optimizer:loss avgErr 0.012714211946021    \n",
    "    xps:1432747515:1:optimizer:confusion accuracy = 0.8877  \n",
    "    xps:1432747515:1:validator:confusion accuracy = 0.9211  \n",
    "    xps:1432747515:1:tester:confusion accuracy = 0.9292 \n",
    "    ==> epoch # 2 for optimizer :   \n",
    "    ==> example speed = 4526.7213369494 examples/s  \n",
    "    xps:1432747515:1:optimizer:loss avgErr 0.0072034133582363   \n",
    "    xps:1432747515:1:optimizer:confusion accuracy = 0.93302 \n",
    "    xps:1432747515:1:validator:confusion accuracy = 0.9405  \n",
    "    xps:1432747515:1:tester:confusion accuracy = 0.9428 \n",
    "    ==> epoch # 3 for optimizer :   \n",
    "    ==> example speed = 4486.8207535058 examples/s  \n",
    "    xps:1432747515:1:optimizer:loss avgErr 0.0056732489919492   \n",
    "    xps:1432747515:1:optimizer:confusion accuracy = 0.94704 \n",
    "    xps:1432747515:1:validator:confusion accuracy = 0.9512  \n",
    "    xps:1432747515:1:tester:confusion accuracy = 0.9518 \n",
    "    ==> epoch # 4 for optimizer :   \n",
    "    ==> example speed = 4524.4831336064 examples/s  \n",
    "    xps:1432747515:1:optimizer:loss avgErr 0.0047361240094285   \n",
    "    xps:1432747515:1:optimizer:confusion accuracy = 0.95672 \n",
    "    xps:1432747515:1:validator:confusion accuracy = 0.9565  \n",
    "    xps:1432747515:1:tester:confusion accuracy = 0.9584 \n",
    "    ==> epoch # 5 for optimizer :   \n",
    "    ==> example speed = 4527.7260154406 examples/s  \n",
    "    xps:1432747515:1:optimizer:loss avgErr 0.0041567858616232   \n",
    "    xps:1432747515:1:optimizer:confusion accuracy = 0.96188 \n",
    "    xps:1432747515:1:validator:confusion accuracy = 0.9603  \n",
    "    xps:1432747515:1:tester:confusion accuracy = 0.9613 \n",
    "    SaveToFile: saving to /home/nicholas/save/xps:1432747515:1.dat  \n",
    "    ==> epoch # 6 for optimizer :   \n",
    "    ==> example speed = 4519.2735741475 examples/s  \n",
    "    xps:1432747515:1:optimizer:loss avgErr 0.0037086909102431   \n",
    "    xps:1432747515:1:optimizer:confusion accuracy = 0.9665  \n",
    "    xps:1432747515:1:validator:confusion accuracy = 0.9602  \n",
    "    xps:1432747515:1:tester:confusion accuracy = 0.9629 \n",
    "    ==> epoch # 7 for optimizer :   \n",
    "    ==> example speed = 4528.1356378239 examples/s  \n",
    "    xps:1432747515:1:optimizer:loss avgErr 0.0033203622647625   \n",
    "    xps:1432747515:1:optimizer:confusion accuracy = 0.97062 \n",
    "    xps:1432747515:1:validator:confusion accuracy = 0.966   \n",
    "    xps:1432747515:1:tester:confusion accuracy = 0.9665 \n",
    "    SaveToFile: saving to /home/nicholas/save/xps:1432747515:1.dat  \n",
    "    \n",
    "After 5 epochs, the experiment starts early-stopping by saving to disk the version of the model with the lowest `xps:1432747515:1:validator:confusion accuracy`. The first part of that string (`xps:1432747515:1`) is the unique id of the experiment. It concatenates the hostname of the computer (`xps` in this case) and a time-stamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the saved Experiment\n",
    "\n",
    "The experiment is saved at `/home/nicholas/save/xps:1432747515:1.dat`. You can load it and access the `model` with :\n",
    "\n",
    "    require 'dp'\n",
    "    require 'cuda' -- if you used cmd-line argument --cuda\n",
    "\n",
    "    xp = torch.load(\"/home/nicholas/save/xps:1432747515:1.dat\")\n",
    "    model = xp:model()\n",
    "    print(torch.type(model))\n",
    "    nn.Serial\n",
    "    \n",
    "For efficiency, the `model` here is decorated with a nn.Serial. You can access the `model` you passed to the experiment by adding :\n",
    "\n",
    "    model = model.module\n",
    "    print(torch.type(model))\n",
    "    nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
